{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = r\"A:\\lingu's data\\helmet\\train\"\n",
    "validation_dir = r\"A:\\lingu's data\\helmet\\validation\"\n",
    "test_dir = r\"A:\\lingu's data\\helmet\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\S R SURJIT KUMAR\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 173 images belonging to 2 classes.\n",
      "Found 39 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "IMAGE_SIZE = [64, 64]  \n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "                                    rescale=1./255,   \n",
    "                                    shear_range=0.2, \n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    preprocessing_function=preprocess_input)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(training_dir, target_size = IMAGE_SIZE, batch_size = 200, class_mode = 'categorical')\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = IMAGE_SIZE, batch_size = 200, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for getting number of files\n",
    "image_files = glob(training_dir + '/*/*.jp*g')\n",
    "valid_image_files = glob(validation_dir + '/*/*.jp*g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes = 2\n"
     ]
    }
   ],
   "source": [
    "# getting the number of classes i.e. type of fruits\n",
    "folders = glob(training_dir + '/*')\n",
    "num_classes = len(folders)\n",
    "print ('Total Classes = ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\S R SURJIT KUMAR\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\S R SURJIT KUMAR\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\S R SURJIT KUMAR\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.applications import VGG16\n",
    "\n",
    "IMAGE_SIZE = [64, 64]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "\n",
    "vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  # input_shape = (64,64,3) as required by VGG\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(num_classes, activation = 'softmax')(x)  \n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14718786 (56.15 MB)\n",
      "Trainable params: 4098 (16.01 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S R SURJIT KUMAR\\AppData\\Local\\Temp\\ipykernel_36260\\1050353050.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(training_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\S R SURJIT KUMAR\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\S R SURJIT KUMAR\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.6358WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3000 batches). You may need to use the repeat() function when building your dataset.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6522 - accuracy: 0.6358 - val_loss: 0.6956 - val_accuracy: 0.6154\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.6197 - accuracy: 0.6474\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.6030 - accuracy: 0.6763\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.5678 - accuracy: 0.7225\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.5453 - accuracy: 0.7630\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.5329 - accuracy: 0.7688\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.5082 - accuracy: 0.7688\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.5022 - accuracy: 0.7630\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.4878 - accuracy: 0.7630\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.4845 - accuracy: 0.7746\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 0.4594 - accuracy: 0.8035\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.4467 - accuracy: 0.8208\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 0.4454 - accuracy: 0.8092\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.4336 - accuracy: 0.8035\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.4313 - accuracy: 0.7977\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.4405 - accuracy: 0.8035\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.4167 - accuracy: 0.7861\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.4028 - accuracy: 0.7919\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.4186 - accuracy: 0.8208\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.3864 - accuracy: 0.8439\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.4024 - accuracy: 0.8092\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.3812 - accuracy: 0.8324\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 0.3794 - accuracy: 0.8208\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 0.3616 - accuracy: 0.8671\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.3395 - accuracy: 0.8844\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 0.3603 - accuracy: 0.8497\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 0.3456 - accuracy: 0.8671\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3616 - accuracy: 0.8439\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3496 - accuracy: 0.8497\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3120 - accuracy: 0.9017\n"
     ]
    }
   ],
   "source": [
    "training_images = 37836\n",
    "validation_images = 12709\n",
    "\n",
    "history = model.fit_generator(training_generator,\n",
    "                   epochs = 30,  # change this for better results\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = 3000)  # this should be equal to total number of images in validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S R SURJIT KUMAR\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(r\"A:\\lingu's data\\helmet\\hel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[1.0000000e+00 1.0227849e-16]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "input=r\"A:\\lingu's data\\helmet\\test\\with helment\\BikesHelmets509.png\"\n",
    "model_path = r\"A:\\lingu's data\\helmet\\hel.h5\"\n",
    "loaded_model = load_model(model_path)\n",
    "img = tf.keras.preprocessing.image.load_img(input, target_size=(64, 64))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.array([img_array]) \n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with helment\n",
      "without helment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "class_names=[]\n",
    "directory_path = r\"A:\\lingu's data\\helmet\\train\"\n",
    "file_names = os.listdir(directory_path)\n",
    "for file_name in file_names:\n",
    "    class_names.append(file_name)\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'with helment'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class_id = np.argmax(predictions, axis = 1)\n",
    "print(class_id)\n",
    "class_names[class_id.item()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pak' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mpak\u001b[49m\u001b[38;5;241m.\u001b[39mindexmodel\u001b[38;5;241m.\u001b[39mModelPredictor(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMain\u001b[39m\u001b[38;5;124m\"\u001b[39m, current_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, input_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pak' is not defined"
     ]
    }
   ],
   "source": [
    "import pak\n",
    "predictor = pak.indexmodel.ModelPredictor(column=\"Main\", current_index=None, input_file=input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
